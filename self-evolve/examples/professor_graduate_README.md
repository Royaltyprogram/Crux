# Professor + Graduate Self-Evolve System with OpenAI Responses API

## ê°œìš”

Professor + Graduate Self-Evolve Systemì€ ë³µì¡í•œ ìˆ˜í•™ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ê³„ì¸µì  AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤. OpenAIì˜ ìµœì‹  **Responses API**ë¥¼ í™œìš©í•˜ì—¬ ìƒíƒœ ê´€ë¦¬ì™€ ë„êµ¬ ì‚¬ìš©ì„ í¬ê²Œ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

### ì£¼ìš” êµ¬ì„±ìš”ì†Œ:

1. **Professor Model**: Chain-of-Thought (CoT) reasoningì„ ìˆ˜í–‰í•˜ë©° í•„ìš”ì‹œ ì „ë¬¸ê°€ë¥¼ í˜¸ì¶œ
2. **Graduate Workers**: íŠ¹ì • ë¶„ì•¼ì— íŠ¹í™”ëœ ì „ë¬¸ê°€ë¡œ, self-evolve mechanismì„ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ë‹µë³€ ì œê³µ
3. **Responses API í†µí•©**: ìƒíƒœ ê´€ë¦¬, ë„êµ¬ ì‚¬ìš©, ëŒ€í™” ì—°ì†ì„±ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
Professor (CoT Reasoning with Responses API)
    â”‚
    â”œâ”€ Native Function Call â†’ Graduate Worker 1 (number theory specialist)
    â”‚                              â””â”€ Self-Evolve Process (ìµœëŒ€ 5 iterations)
    â”‚                                    â”œâ”€ Specialized Instructions
    â”‚                                    â”œâ”€ Code Interpreter í™œìš©
    â”‚                                    â””â”€ Domain-specific Validation
    â”‚
    â”œâ”€ Native Function Call â†’ Graduate Worker 2 (integration expert)
    â”‚                              â””â”€ Self-Evolve Process (ìµœëŒ€ 5 iterations)
    â”‚
    â”œâ”€ State Management (OpenAIê°€ ìë™ ê´€ë¦¬)
    â”‚   â”œâ”€ previous_response_idë¡œ ëŒ€í™” ì—°ì†ì„±
    â”‚   â””â”€ ìë™ context ê´€ë¦¬
    â”‚
    â””â”€ ìµœì¢… ë‹µë³€ ì¢…í•© (ëª¨ë“  ì „ë¬¸ê°€ ê²°ê³¼ í†µí•©)
```

## ğŸ†• Responses APIì˜ ì£¼ìš” ì¥ì 

### 1. **ìë™ ìƒíƒœ ê´€ë¦¬**

- OpenAIê°€ ëŒ€í™” ìƒíƒœë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬
- `previous_response_id`ë¡œ ê°„í¸í•œ ëŒ€í™” ì—°ì†ì„±
- ë³µì¡í•œ context ê´€ë¦¬ ë¶ˆí•„ìš”

### 2. **ë„¤ì´í‹°ë¸Œ ë„êµ¬ í†µí•©**

- `code_interpreter` ìë™ í™œìš©
- Function callingì´ API ë ˆë²¨ì—ì„œ ì§ì ‘ ì§€ì›
- ë„êµ¬ í˜¸ì¶œê³¼ ê²°ê³¼ ì²˜ë¦¬ ìë™í™”

### 3. **Reasoning Models ìµœì í™”**

- o3, o4 ëª¨ë¸ì˜ ì¶”ë¡  ê³¼ì • ì™„ì „ ì§€ì›
- `reasoning_effort`, `reasoning_summary` íŒŒë¼ë¯¸í„° í™œìš©
- ë‹¤ë‹¨ê³„ function calling ë£¨í”„ ìë™ ì²˜ë¦¬

## ì‚¬ìš© ë°©ë²•

### 1. í™˜ê²½ ì„¤ì •

```bash
export OPENAI_API_KEY="your-api-key"

# ì„ íƒì  ëª¨ë¸ ì„¤ì •
export PROFESSOR_MODEL="o3"        # ê¸°ë³¸ê°’: o3
export EVALUATOR_MODEL="o3"        # ê¸°ë³¸ê°’: o3
export SIMPLE_MODEL="gpt-4o"       # í…ŒìŠ¤íŠ¸ìš©
```

### 2. ì‹¤í–‰

#### ì „ì²´ ì˜ˆì œ ì‹¤í–‰ (o3 ëª¨ë¸, Responses API):

```bash
cd examples
python professor_graduate_example.py
```

#### ê°„ë‹¨í•œ ì˜ˆì œ ì‹¤í–‰ (gpt-4o ëª¨ë¸):

```bash
python professor_graduate_example.py --simple
```

#### Responses API ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸:

```bash
python professor_graduate_example.py --test
```

#### ì§ì ‘ ëª¨ë“ˆë¡œ ì‹¤í–‰:

```python
from tooliense.examples.professor_graduate_example import professor_graduate_example
professor_graduate_example()
```

### 3. ì»¤ìŠ¤í…€ ë¬¸ì œ ì„¤ì •

í™˜ê²½ ë³€ìˆ˜ë¡œ ë¬¸ì œ íŒŒì¼ ì§€ì •:

```bash
export PROBLEM_FILE="./tooliense/examples/problems/your_problem.xml"
python professor_graduate_example.py
```

## ì‘ë™ ì›ë¦¬

### Professorì˜ ì—­í•  (Responses API ê¸°ë°˜):

1. **ë¬¸ì œ ë¶„ì„**: Chain-of-Thought reasoning ìˆ˜í–‰
2. **ì „ë¬¸ê°€ ì‹ë³„**: íŠ¹ì • ì „ë¬¸ ì§€ì‹ì´ í•„ìš”í•œ ë¶€ë¶„ íŒŒì•…
3. **Function Calling**: `consult_graduate_specialist` ë„¤ì´í‹°ë¸Œ í˜¸ì¶œ
4. **ìƒíƒœ ê´€ë¦¬**: OpenAIê°€ ìë™ìœ¼ë¡œ ëŒ€í™” ìƒíƒœ ê´€ë¦¬
5. **ê²°ê³¼ í†µí•©**: ëª¨ë“  ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ë„ì¶œ

### Graduate Workerì˜ Enhanced Self-Evolve Process:

1. **ì „ë¬¸í™”ëœ Instructions**: ê° ë„ë©”ì¸ì— íŠ¹í™”ëœ system prompt
2. **Code Interpreter í™œìš©**: ìˆ˜í•™ì  ê³„ì‚°ê³¼ ê²€ì¦ ìë™í™”
3. **Iteration 1**: ì´ˆê¸° ì „ë¬¸ê°€ ë‹µë³€ ìƒì„±
4. **Evaluation**: ë‹µë³€ í‰ê°€ ë° í”¼ë“œë°± ìƒì„± (Code Interpreter í¬í•¨)
5. **AI Prompt Refinement**: í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê°œì„ 
6. **Iterations 2-5**: ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
7. **ìˆ˜ë ´ ê°ì§€**: ë™ì¼í•œ ë‹µë³€ì´ 3ë²ˆ ì—°ì† ë‚˜ì˜¤ë©´ ì¡°ê¸° ì¢…ë£Œ
8. **ì„±ëŠ¥ ë©”íŠ¸ë¦­**: ìˆ˜ë ´ í’ˆì§ˆ ë° ì „ë¬¸ì„± íš¨ê³¼ ì¸¡ì •

## ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥ë“¤

### 1. **ëŒ€í™” ì—°ì†ì„±**

```python
# ì²« ë²ˆì§¸ ì§ˆë¬¸
professor = ProfessorModel(config)
answer1 = professor.generate("ë³µì¡í•œ ìˆ˜í•™ ë¬¸ì œ...")

# í›„ì† ì§ˆë¬¸ (ìƒíƒœ ìë™ ìœ ì§€)
answer2 = professor.continue_conversation("ì „ë¬¸ê°€ë“¤ì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ìš”ì•½í•´ì¤˜")
```

### 2. **í–¥ìƒëœ ì „ë¬¸ê°€ ì‹œìŠ¤í…œ**

```python
# ì „ë¬¸ê°€ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
result = graduate_worker.solve_specialized_task("number theory specialist", task)
print(f"ì „ë¬¸ì„± íš¨ê³¼: {result['performance_metrics']['specialization_effectiveness']}")
print(f"ìˆ˜ë ´ í’ˆì§ˆ: {result['performance_metrics']['average_iteration_quality']}")
```

### 3. **ì‹¤ì‹œê°„ ìƒíƒœ ëª¨ë‹ˆí„°ë§**

```python
summary = professor.get_consultation_summary()
print(f"Response ID: {summary['current_response_id']}")
print(f"ì‹¤ì‹œê°„ ìƒë‹´ ìˆ˜: {summary['total_consultations']}")
```

## ì˜ˆì‹œ ì¶œë ¥

```
=== Professor with Graduate Self-Evolve Specialists (Responses API) ===
Question: [ord density ë¬¸ì œ ë‚´ìš©]
--------------------------------------------------------------------------------

Professor: "ì´ ë¬¸ì œëŠ” number theoryì— ê´€í•œ ê²ƒì…ë‹ˆë‹¤. ord_p(a)ì˜ ì„±ì§ˆì„ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤..."

[Native Function Call]: consult_graduate_specialist
  - Specialization: "number theory specialist"
  - Task: "ord_p(a)ì˜ multiplicative order ì„±ì§ˆ ë¶„ì„"

Graduate Worker (number theory specialist) - Enhanced Process:
  â”œâ”€ Specialized Instructions: "You are a specialized number theory specialist..."
  â”œâ”€ Code Interpreter: ìë™ í™œì„±í™”
  â””â”€ Self-Evolve Iterations:
      â”œâ”€ Iteration 1: "ord_p(a)ëŠ”..." â†’ Evaluation: "ë” ì •í™•í•œ ë¶„ì„ í•„ìš”"
      â”œâ”€ Iteration 2: "ê°œì„ ëœ ë¶„ì„..." â†’ Evaluation: "ì¢‹ìŒ"
      â””â”€ Iteration 3: "ìµœì¢… ë¶„ì„..." â†’ ìˆ˜ë ´ (specialization_effectiveness: highly_specialized)

Professor: "ì „ë¬¸ê°€ì˜ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤..."

[ìµœì¢… ë‹µë³€]
<answer>500000</answer>

Graduate Consultations Summary:
- Total consultations: 2
- Graduate workers created: 2
- Response ID: resp_abc123def456

Testing conversation continuation...
Follow-up question: Can you summarize the key insights from the specialists' work?
Professor's response: Based on the specialists' work, the key insights are...
```

## ë¡œê·¸ ë° ê²°ê³¼

### ë¡œê·¸ ìœ„ì¹˜:

- **ë©”ì¸ ë¡œê·¸**: `./tooliense/logs/professor_graduate_responses.jsonl`
- **ê°„ë‹¨í•œ ì˜ˆì œ**: `./tooliense/logs/professor_graduate_simple_responses.jsonl`
- **ì„¸ì…˜ ê²°ê³¼**: `./tooliense/logs/professor_graduate_responses_[timestamp].json`

### ê²°ê³¼ íŒŒì¼ êµ¬ì¡°:

```json
{
  "timestamp": "20241225_143022",
  "api_version": "responses_api",
  "question": "...",
  "final_answer": "...",
  "execution_time_seconds": 45.2,
  "consultation_summary": {
    "total_consultations": 2,
    "current_response_id": "resp_abc123",
    "consultations": [...]
  },
  "system_config": {
    "professor_model": "o3",
    "evaluator_model": "o3",
    "reasoning_effort": "high",
    "enable_code_interpreter": true
  }
}
```

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ëª¨ë¸ í˜¸í™˜ì„±:

- **Professor**: o3, o4, gpt-4o ëª¨ë“  ëª¨ë¸ ì§€ì›
- **Graduate Workers**: o3, o4, gpt-4o ëª¨ë“  ëª¨ë¸ ì§€ì›
- **Reasoning Models**: o3, o4ì—ì„œ ìµœì  ì„±ëŠ¥ (reasoning_effort, reasoning_summary í™œìš©)

### API ê¸°ëŠ¥:

- **Responses API**: í•„ìˆ˜ (ìƒíƒœ ê´€ë¦¬, ë„êµ¬ í†µí•©)
- **Code Interpreter**: ìë™ í™œì„±í™” (ìˆ˜í•™ì  ê²€ì¦)
- **Function Calling**: ë„¤ì´í‹°ë¸Œ ì§€ì›

## ê³ ê¸‰ ì„¤ì •

### 1. Reasoning íŒŒë¼ë¯¸í„° ì¡°ì •:

```python
config = FrameworkConfig(
    generator_config=ModelConfig(
        reasoning_effort="high",      # low, medium, high
        reasoning_summary="auto",     # auto, concise, detailed, none
        truncation="auto"             # auto, disabled
    )
)
```

### 2. ì „ë¬¸ê°€ íŠ¹í™” ì„¤ì •:

```python
# ë„ë©”ì¸ë³„ iteration ìˆ˜ ì¡°ì •
config.max_iterations = 3  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
config.max_iterations = 7  # ë³µì¡í•œ ë¬¸ì œìš©
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§:

```python
# ì „ë¬¸ê°€ ì„±ëŠ¥ ë¶„ì„
for consultation in professor.consultation_history:
    metrics = consultation['performance_metrics']
    print(f"ìˆ˜ë ´ í’ˆì§ˆ: {metrics['average_iteration_quality']}")
    print(f"ì „ë¬¸ì„± íš¨ê³¼: {metrics['specialization_effectiveness']}")
```

## ì£¼ìš” íŠ¹ì§•

1. **ğŸ”„ Stateful Architecture**: OpenAIê°€ ëŒ€í™” ìƒíƒœ ìë™ ê´€ë¦¬
2. **ğŸ› ï¸ Native Tool Integration**: Code Interpreter, Function Calling ì™„ì „ í†µí•©
3. **ğŸ§  Reasoning Model Optimization**: o3/o4 ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ ì™„ì „ í™œìš©
4. **ğŸ“Š Enhanced Metrics**: ì „ë¬¸ì„± íš¨ê³¼ ë° ìˆ˜ë ´ í’ˆì§ˆ ìë™ ì¸¡ì •
5. **ğŸ’¬ Conversation Continuity**: ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì—°ì†ì„±
6. **ğŸ” Transparent Process**: ëª¨ë“  consultationê³¼ iteration ì™„ì „ ë¡œê¹…
7. **âš¡ Improved Performance**: Responses APIë¡œ ë” ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ì²˜ë¦¬

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ê¸°ì¡´ Chat Completions API vs Responses API:

- **ìƒíƒœ ê´€ë¦¬**: ìˆ˜ë™ â†’ ìë™ (95% ì½”ë“œ ê°ì†Œ)
- **ë„êµ¬ ì‚¬ìš©**: ë³µì¡í•œ ë£¨í”„ â†’ ë„¤ì´í‹°ë¸Œ í†µí•©
- **ëŒ€í™” ì—°ì†ì„±**: ë¶ˆê°€ëŠ¥ â†’ ì™„ì „ ì§€ì›
- **ì²˜ë¦¬ ì†ë„**: ë‹¤ì¤‘ API í˜¸ì¶œ â†’ ë‹¨ì¼ API í˜¸ì¶œë¡œ ìµœì í™”
